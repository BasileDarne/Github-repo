{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "# import numpy as np\n",
    "import random\n",
    "\n",
    "def read_cifar_batch(batch):\n",
    "    \"\"\"\n",
    "    batch : is a string, path of a single batch\n",
    "    returns : matrix data, vector labels\n",
    "    \"\"\"\n",
    "    with open(batch, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    # print(dict.keys())\n",
    "    labels = dict[b'labels']\n",
    "    data = dict[b'data']\n",
    "    return(data, labels)\n",
    "\n",
    "def read_cifar(path):\n",
    "    \"\"\"\n",
    "    parameter : path of directory containing 5 data batches + test batch \n",
    "    returns : data, labels\n",
    "    \"\"\"\n",
    "    batches = [\"data_batch_1/\", \"data_batch_2/\", \"data_batch_3/\", \"data_batch_4/\", \"data_batch_5/\", \"test_batch/\"]\n",
    "    list_data = []\n",
    "    list_labels = []\n",
    "    for name in batches:\n",
    "        file_path = os.path.join(path, name)\n",
    "        data_i, labels_i = read_cifar_batch(file_path)\n",
    "        list_data.append(data_i)\n",
    "        list_labels.append(labels_i)\n",
    "    data = np.concatenate(list_data)\n",
    "    labels = np.concatenate(list_labels)\n",
    "    return data, labels\n",
    "\n",
    "def split_dataset(data, labels, split):\n",
    "    nb_im = len(data)\n",
    "    shuffled = [i for i in range(0, nb_im)]\n",
    "    np.random.shuffle(shuffled) # liste d'entiers mélangés sans répétition entre 0 et 59 999 : indices des images\n",
    "\n",
    "    split_index = round(split*nb_im)\n",
    "    # print(split_index)\n",
    "    train_index = shuffled[:split_index]\n",
    "    test_index = shuffled[split_index:]\n",
    "    data_train = []\n",
    "    labels_train = []\n",
    "    for i in train_index:\n",
    "        data_train.append(data[i])\n",
    "        labels_train.append(labels[i])\n",
    "    \n",
    "    data_test = []\n",
    "    labels_test = []\n",
    "    for i in test_index:\n",
    "        data_test.append(data[i])\n",
    "        labels_test.append(labels[i])\n",
    "\n",
    "    data_train = np.array(data_train, dtype=np.float32)\n",
    "    data_test = np.array(data_test, dtype=np.int64)\n",
    "    labels_train = np.array(labels_train, dtype=np.float32)\n",
    "    labels_test = np.array(labels_test)\n",
    "    \n",
    "    return(data_train, labels_train, data_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest neighboors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.696938456699069\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def distance_matrix(matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    a, b are two matrices of same dimension\n",
    "    returns the L2 Euclidian distance matrix\n",
    "    \"\"\"\n",
    "    # matrix1_expanded = np.expand_dims(matrix1, axis=1)\n",
    "    # matrix2_expanded = np.expand_dims(matrix2, axis=0)\n",
    "\n",
    "    # Compute element-wise squared differences\n",
    "    squared_diff = np.sum((matrix1 - matrix2)**2)\n",
    "\n",
    "    # Compute the L2 Euclidean distance matrix\n",
    "    dists = np.sqrt(squared_diff)\n",
    "\n",
    "    return dists\n",
    "\n",
    "# Example usage:\n",
    "matrix1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "matrix2 = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "result = distance_matrix(matrix1, matrix2)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def distance_matrix(a, b):\n",
    "    \"\"\"\n",
    "    returns the L2 Euclidian distance matrix\n",
    "    \"\"\"\n",
    "    print(a.shape, b.shape)\n",
    "    a2 = np.sum(np.square(a), axis=1, keepdims=True) # sum over each line \n",
    "    b2 = np.sum(np.square(b), axis=1, keepdims=True)\n",
    "\n",
    "    dists = np.sqrt(a2 + b2.T - 2 * np.dot(a, b.T))\n",
    "    return dists\n",
    "\n",
    "# Select the most frequent one\n",
    "def democracy(arr):\n",
    "    \"\"\"\n",
    "    majority vote in the labels array \n",
    "    returns the most frequent label in the array\n",
    "    \"\"\"\n",
    "    values, count = np.unique(arr, return_counts=True)\n",
    "    return values[np.argmax(count)]\n",
    "\n",
    "def knn_predict(dists, labels_train, k):\n",
    "\n",
    "    nearest_indices = np.argsort(dists.T)[:, :k]\n",
    "    nearest_labels = [labels_train[i] for i in nearest_indices]\n",
    "    predictions = np.array([democracy(arr) for arr in nearest_labels])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def evaluate_knn(data_train, labels_train, data_test, labels_test, k):\n",
    "\n",
    "    dists = distance_matrix(data_train, data_test)      \n",
    "    prediction = knn_predict(dists, labels_train, k)\n",
    "\n",
    "    correct = 0\n",
    "    for pred, test in zip(prediction, labels_test):\n",
    "        if pred == test:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / len(labels_test)\n",
    "\n",
    "\n",
    "def plot_evaluate_knn(data_train, labels_train, data_test, labels_test):\n",
    "\n",
    "    dists = distance_matrix(data_train, data_test)\n",
    "    sorted_dist = np.argsort(dists.T)\n",
    "\n",
    "    k_list = [i for i in range(1, 21)]\n",
    "    accuracies = []\n",
    "    for k in range(1, 21):\n",
    "        print(\"\\n Evaluating k=%d\" % k)\n",
    "        accuracies.append(evaluate_knn(\n",
    "            data_train=data_train,\n",
    "            labels_train=labels_train,\n",
    "            data_test=data_test,\n",
    "            labels_test=labels_test,\n",
    "            k=k\n",
    "        ))\n",
    "\n",
    "    plt.title(\"Variation of the accuracy as a function of k\")\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.grid()\n",
    "    plt.plot(k_list, accuracies, 'o-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=1\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=2\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=3\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=4\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=5\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=6\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=7\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=8\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=9\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=10\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=11\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=12\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=13\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=14\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=15\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=16\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=17\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=18\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=19\n",
      "(54000, 3072) (6000, 3072)\n",
      "\n",
      " Evaluating k=20\n",
      "(54000, 3072) (6000, 3072)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, labels = read_cifar(\"./data/cifar-10-batches-py\")\n",
    "\n",
    "split = 0.9\n",
    "data_train, labels_train, data_test, labels_test = split_dataset(data, labels, split)\n",
    "\n",
    "plot_evaluate_knn(data_train, labels_train, data_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3]\n",
      "  [4 5 6]]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(np.expand_dims(matrix1, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(dists, labels_train, k):\n",
    "    \"\"\"\n",
    "    dists : distance matrix between train set and test set\n",
    "    k : number of labels\n",
    "    \n",
    "    returns the predicted labels for the elements of data_test\n",
    "    \"\"\"\n",
    "    # Ensure k is not greater than the number of training samples\n",
    "    if k > len(labels_train):\n",
    "        raise ValueError(\"Number of neighbors (k) cannot be greater than the number of training samples\")\n",
    "\n",
    "    # Get the indices of the k nearest neighbors for each test sample\n",
    "    indices = np.argsort(dists, axis=1)[:, :k]\n",
    "\n",
    "    # Get the labels of the k nearest neighbors\n",
    "    k_nearest_labels = labels_train[indices]\n",
    "\n",
    "    # For each test sample, find the most common label among its k nearest neighbors\n",
    "    predicted_labels = np.array([np.argmax(np.bincount(labels)) for labels in k_nearest_labels])\n",
    "\n",
    "    return predicted_labels\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'dists' is the distance matrix, 'labels_train' is the training labels, and 'k' is the number of neighbors\n",
    "# 'data_test' is the test data for which you want to predict labels\n",
    "\n",
    "# predicted_labels = knn_predict(dists, labels_train, k)\n",
    "# print(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn(data_train, labels_train, data_test, labels_test, k):\n",
    "    \"\"\"\n",
    "    returns classification rate (accuracy)\n",
    "    \"\"\"\n",
    "    dists = distance_matrix(data_train, data_test)\n",
    "    pred_labels = knn_predict(dists, labels_train, k)\n",
    "\n",
    "    accuracy = sum(pred_labels == labels_test)/len(labels_test)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape : (10000, 3072) - labels shape : (10000,)\n",
      "data shape : (60000, 3072) - labels shape : (60000,)\n",
      "size labels_train : 45000 - 45000\n",
      "size labels_test : 15000 - 15000\n",
      "(45000, 3072) (15000, 3072)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os \n",
    "# import numpy as np\n",
    "import random\n",
    "\n",
    "def read_cifar_batch(batch):\n",
    "    \"\"\"\n",
    "    batch : is a string, path of a single batch\n",
    "    returns : matrix data, vector labels\n",
    "    \"\"\"\n",
    "    with open(batch, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    # print(dict.keys())\n",
    "    labels = dict[b'labels']\n",
    "    data = dict[b'data']\n",
    "    return(data, labels)\n",
    "\n",
    "def read_cifar(path):\n",
    "    \"\"\"\n",
    "    parameter : path of directory containing 5 data batches + test batch \n",
    "    returns : data, labels\n",
    "    \"\"\"\n",
    "    batches = [\"data_batch_1/\", \"data_batch_2/\", \"data_batch_3/\", \"data_batch_4/\", \"data_batch_5/\", \"test_batch/\"]\n",
    "    list_data = []\n",
    "    list_labels = []\n",
    "    for name in batches:\n",
    "        file_path = os.path.join(path, name)\n",
    "        data_i, labels_i = read_cifar_batch(file_path)\n",
    "        list_data.append(data_i)\n",
    "        list_labels.append(labels_i)\n",
    "    data = np.concatenate(list_data)\n",
    "    labels = np.concatenate(list_labels)\n",
    "    return data, labels\n",
    "\n",
    "def split_dataset(data, labels, split):\n",
    "    nb_im = len(data)\n",
    "    shuffled = [i for i in range(0, nb_im)]\n",
    "    np.random.shuffle(shuffled) # liste d'entiers mélangés sans répétition entre 0 et 59 999 : indices des images\n",
    "\n",
    "    split_index = round(split*nb_im)\n",
    "    # print(split_index)\n",
    "    train_index = shuffled[:split_index]\n",
    "    test_index = shuffled[split_index:]\n",
    "    data_train = []\n",
    "    labels_train = []\n",
    "    for i in train_index:\n",
    "        data_train.append(data[i])\n",
    "        labels_train.append(labels[i])\n",
    "    \n",
    "    data_test = []\n",
    "    labels_test = []\n",
    "    for i in test_index:\n",
    "        data_test.append(data[i])\n",
    "        labels_test.append(labels[i])\n",
    "\n",
    "    data_train = np.array(data_train, dtype=np.float32)\n",
    "    data_test = np.array(data_test, dtype=np.int64)\n",
    "    labels_train = np.array(labels_train, dtype=np.float32)\n",
    "    labels_test = np.array(labels_test)\n",
    "    \n",
    "    return(data_train, labels_train, data_test, labels_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    path = \"D:/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/data/cifar-10-batches-py/\"\n",
    "\n",
    "    # Test read_cifar_batch\n",
    "    batch = \"D:/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/data/cifar-10-batches-py/data_batch_1/\"\n",
    "    data, labels = read_cifar_batch(batch)\n",
    "    print(f\"data shape : {np.shape(data)} - labels shape : {np.shape(labels)}\")\n",
    "\n",
    "    # Test read_cifar\n",
    "    data, labels = read_cifar(path)\n",
    "    print(f\"data shape : {np.shape(data)} - labels shape : {np.shape(labels)}\")\n",
    "    \n",
    "    # Test split_dataset\n",
    "    data_train, labels_train, data_test, labels_test = split_dataset(data, labels, 0.75)\n",
    "    \n",
    "    print(f\"size labels_train : {len(data_train)} - {len(labels_train)}\")\n",
    "    print(f\"size labels_test : {len(data_test)} - {len(labels_test)}\")\n",
    "    print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\ECL\\3A\\MOD\\IA\\TD1\\mod_4_6-td1-main\\TP1.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m N, din \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mshape(data_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(N, din)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(labels_test\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "N, din = np.shape(data_test)\n",
    "print(N, din)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2] [3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = 30  # number of input data\n",
    "d_in = 3  # input dimension\n",
    "d_h = 3  # number of neurons in the hidden layer\n",
    "d_out = 2  # output dimension (number of neurons of the output layer)\n",
    "\n",
    "# Random initialization of the network weights and biaises\n",
    "w1 = 2 * np.random.rand(d_in, d_h) - 1  # first layer weights\n",
    "b1 = np.zeros((1, d_h))  # first layer biaises\n",
    "w2 = 2 * np.random.rand(d_h, d_out) - 1  # second layer weights\n",
    "b2 = np.zeros((1, d_out))  # second layer biaises\n",
    "\n",
    "data = np.random.rand(N, d_in)  # create a random data\n",
    "targets = np.random.rand(N, d_out)  # create a random targets\n",
    "\n",
    "# Forward pass\n",
    "a0 = data # the data are the input of the first layer\n",
    "z1 = np.matmul(a0, w1) + b1  # input of the hidden layer\n",
    "a1 = 1 / (1 + np.exp(-z1))  # output of the hidden layer (sigmoid activation function)\n",
    "z2 = np.matmul(a1, w2) + b2  # input of the output layer\n",
    "a2 = 1 / (1 + np.exp(-z2))  # output of the output layer (sigmoid activation function)\n",
    "predictions = a2  # the predicted values are the outputs of the output layer\n",
    "\n",
    "# Compute loss (MSE)\n",
    "loss = np.mean(np.square(predictions - targets))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Create a Python file named `mlp.py`. Use the above code to write the function `learn_once_mse` taking as parameters:\n",
    "- `w1`, `b1`, `w2`, `b2` the weights\n",
    "- `data` a matrix of shape (`batch_size` x `d_in`)\n",
    "- `targets` a matrix of shape (`batch_size` x `d_out`)\n",
    "- `learning_rate` the learning rate\n",
    "\n",
    "performs one gradient descent step by step, and returns :\n",
    "- `w1`, `b1`, `w2`, `b2` the updated weights and biases\n",
    "- `loss`, the loss for monitoring purpose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(mat):\n",
    "    \"\"\" \n",
    "    Returns the sigmoid of matrix mat\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-mat))\n",
    "\n",
    "def learn_once_mse(w1, b1, w2, b2, data, targets, learning_rate):\n",
    "    \"\"\" \n",
    "    performs one learning step and one gradient descent\n",
    "    returns the updated weights and biases and the loss for monitoring purpose\n",
    "    \"\"\"\n",
    "    batch_size, d_out = np.shape(targets) # data has a shape of (N, d_out)\n",
    "    # Forward pass\n",
    "    a0 = data # the data are the input of the input layer\n",
    "    z1 = np.matmul(a0, w1) + b1  # input of the hidden layer\n",
    "    a1 = sigmoid(z1) # output of the hidden layer (sigmoid activation function)\n",
    "    z2 = np.matmul(a1, w2) + b2  # input of the output layer\n",
    "    a2 = sigmoid(z2)  # output of the output layer (sigmoid activation function)\n",
    "    predictions = a2  # the predicted values are the outputs of the output layer\n",
    "\n",
    "    # Compute loss (MSE)\n",
    "    loss = np.mean(np.square(predictions - targets))    \n",
    "\n",
    "    # Error backpropagation\n",
    "    dc_da2 = 2/(batch_size*d_out) * (a2 - targets)          # dim : N x d_out\n",
    "    dc_dz2 = dc_da2 * a2 * (1 - a2)                # dim : N x d_out\n",
    "    a1t = np.transpose(a1)                         # dim : d_h x N\n",
    "    dc_dw2 = np.matmul(a1t, dc_dz2)                # dim : d_h x d_out\n",
    "    dc_db2 = np.sum(dc_dz2, axis=0)                # dim : 1 x d_h ; line vector containing the sum of all the values over a line\n",
    "    w2t = np.transpose(w2)                         # dim : d_out x d_h\n",
    "    dc_da1 = np.matmul(dc_dz2, w2t)                # dim : N x d_h\n",
    "    dc_dz1 = dc_da1 * a1 * (1 - a1)                # dim : N x d_h\n",
    "    a0t = np.transpose(a0)                         # dim : d_in x N\n",
    "    dc_dw1 = np.matmul(a0t, dc_dz1)                # dim : d_in x d_h \n",
    "    dc_db1 = np.sum(dc_dz1, axis=0)                # dim :  1 x d_in\n",
    "\n",
    "    # Parameter update\n",
    "    w1 = w1 - learning_rate * dc_dw1\n",
    "    b1 = b1 - learning_rate * dc_db1\n",
    "    w2 = w2 - learning_rate * dc_dw2\n",
    "    b2 = b2 - learning_rate * dc_db2    \n",
    "\n",
    "    return (w1, b1, w2, b2, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]]\n",
      "[4 6 8]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2,3], [3,4,5]])\n",
    "print(a)\n",
    "print(np.sum(a, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Write the function `one_hot`  taking a (n)-D array as parameters and returning the corresponding (n+1)-D one-hot matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# number of classes is d_out\n",
    "def one_hot(m):\n",
    "    res = [[1 if m[i]==j else 0 for j in range(np.max(m)+1)] for i in range(len(m))]\n",
    "    res = np.array(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0]\n",
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vect = np.array([1,2,0])\n",
    "print(vect)\n",
    "print(one_hot(vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Write the function `learn_once_cross_entropy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]]\n",
      "[[6]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1,2,3],[1,2,3]])\n",
    "print(arr)\n",
    "print(np.sum(arr, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    sum_lines = np.sum(exp_z, axis=1, keepdims=True) # sum of values line by line\n",
    "    return exp_z / sum_lines\n",
    "\n",
    "def learn_once_cross_entropy(w1, b1, w2, b2, data, labels_train, learning_rate) :\n",
    "    \"\"\"\n",
    "    performs one learning step and one gradient descent step\n",
    "    returns the updated weights and biases and the loss for monitoring purpose\n",
    "    \"\"\"\n",
    "    # one_hot vector encoding the label\n",
    "    y = one_hot(labels_train) \n",
    "\n",
    "    # Forward pass\n",
    "    a0 = data # the data are the input of the first layer\n",
    "    z1 = np.matmul(a0, w1) + b1  # input of the hidden layer\n",
    "    a1 = sigmoid(z1)  # output of the hidden layer (sigmoid activation function)\n",
    "    z2 = np.matmul(a1, w2) + b2  # input of the output layer\n",
    "    a2 = softmax(z2) # output of the output layer (softmax activation function)\n",
    "    \n",
    "    # Compute loss : cross-entropy loss \n",
    "    loss = -np.mean(y*np.log(a2))  \n",
    "\n",
    "    # Error backpropagation\n",
    "    dc_dz2 = a2 - targets                          # dim : N x d_out\n",
    "    # all the other gradients do not change\n",
    "    a1t = np.transpose(a1)                         # dim : d_h x N\n",
    "    dc_dw2 = np.matmul(a1t, dc_dz2)                # dim : d_h x d_out\n",
    "    dc_db2 = np.sum(dc_dz2, axis=0)                # dim : 1 x d_h ; line vector containing the sum of all the values over a line\n",
    "    w2t = np.transpose(w2)                         # dim : d_out x d_h\n",
    "    dc_da1 = np.matmul(dc_dz2, w2t)                # dim : N x d_h\n",
    "    dc_dz1 = dc_da1 * a1 * (1 - a1)                # dim : N x d_h\n",
    "    a0t = np.transpose(a0)                         # dim : d_in x N\n",
    "    dc_dw1 = np.matmul(a0t, dc_dz1)                # dim : d_in x d_h \n",
    "    dc_db1 = np.sum(dc_dz1, axis=0)                # dim :  1 x d_in\n",
    "\n",
    "    # Parameter update\n",
    "    w1 = w1 - learning_rate * dc_dw1\n",
    "    b1 = b1 - learning_rate * dc_db1\n",
    "    w2 = w2 - learning_rate * dc_dw2\n",
    "    b2 = b2 - learning_rate * dc_db2\n",
    "\n",
    "    # accuracy calculation\n",
    "    true_predictions = np.sum(labels_train == predictions_vect) # true prediction means the prediction is equal to the target\n",
    "    total_predictions = np.shape(labels_test)[0] # number of input data in the batch i.e. number of lines of the labels_train matrix i.e. first dimension of the matrix\n",
    "    accuracy = true_predictions/total_predictions\n",
    "    \n",
    "    # return the accuracy for the training function\n",
    "    return w1, b1, w2, b2, loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Write the function `train_mlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(w1, b1, w2, b2, data_train, labels_train, learning_rate, num_epoch):\n",
    "    \"\"\"\n",
    "    performs num_epoch of training steps\n",
    "    returns final weights and biases\n",
    "    and returns train_accuracies : list of train accuracies accross epochs, list of floats\n",
    "    \"\"\"\n",
    "    train_accuracies = []\n",
    "    for epoch in range(num_epoch):\n",
    "        print(f\"epoch : {epoch}\")\n",
    "        # one training step\n",
    "        w1, b1, w2, b2, loss, accuracy = learn_once_cross_entropy(w1, b1, w2, b2, data_train, labels_train, learning_rate)\n",
    "        print(f\"loss : {loss}\\naccuracy : {accuracy}\\n\")\n",
    "        train_accuracies.append(accuracy)\n",
    "         \n",
    "    return w1, b1, w2, b2, train_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write the function `test_mlp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "m = np.array([[1,2],[3,4],[5,6]])\n",
    "print(m)\n",
    "predictions = np.argmax(m, axis=1)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the network is already trained\n",
    "\n",
    "def test_mlp(w1, b1, w2, b2, data_test, labels_test):\n",
    "    \"\"\"\n",
    "    Only forward pass\n",
    "    Returns the test accuracy\n",
    "    \"\"\"\n",
    "    # code similar to the learn_once_cross_entropy function, but no gradient descent\n",
    "    # one_hot vector encoding the label\n",
    "    y = one_hot(labels_test) \n",
    "\n",
    "    # Forward pass\n",
    "    a0 = data_test # the data are the input of the first layer\n",
    "    z1 = np.matmul(a0, w1) + b1  # input of the hidden layer\n",
    "    a1 = sigmoid(z1)  # output of the hidden layer (sigmoid activation function)\n",
    "    z2 = np.matmul(a1, w2) + b2  # input of the output layer\n",
    "    a2 = softmax(z2) # output of the output layer (softmax activation function)    \n",
    "    \n",
    "    # accuracy \n",
    "    predictions = np.argmax(a2, axis=1) # returns index of the max of each line, returns a line vector\n",
    "    true_predictions = np.sum(labels_test == predictions)\n",
    "    total_predictions = labels_test.shape[0]\n",
    "    test_accuracy = true_predictions/total_predictions\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Write the function `run_mlp_training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mlp_training(data_train, labels_train, data_test, labels_test, d_h, learning_rate, num_epoch):\n",
    "\n",
    "    N, d_in = np.shape(data_train)  # input dimension\n",
    "    d_out = np.shape(labels_test)[0]  # output dimension (number of neurons of the output layer)\n",
    "\n",
    "    # Random initialization of the network weights and biaises\n",
    "    w1 = 2 * np.random.rand(d_in, d_h) - 1  # first layer weights\n",
    "    b1 = np.zeros((1, d_h))  # first layer biaises\n",
    "    w2 = 2 * np.random.rand(d_h, d_out) - 1  # second layer weights\n",
    "    b2 = np.zeros((1, d_out))  # second layer biaises\n",
    "\n",
    "    # Training\n",
    "    w1, b1, w2, b2, train_accuracies = train_mlp(w1, b1, w2, b2, data_train, labels_train, learning_rate, num_epoch)\n",
    "\n",
    "    # Testing\n",
    "    test_accuracy = test_mlp(w1, b1, w2, b2, data_test, labels_test)\n",
    "\n",
    "    return train_accuracies, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. For `split_factor=0.9`, `d_h=64`, `learning_rate=0.1` and `num_epoch=100`, plot the evolution of learning accuracy across learning epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10)\n"
     ]
    }
   ],
   "source": [
    "y = one_hot(labels_test)\n",
    "print(np.shape(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basil\\AppData\\Local\\Temp\\ipykernel_11020\\516218375.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-mat))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (54000,10) (54000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\ECL\\3A\\MOD\\IA\\TD1\\mod_4_6-td1-main\\TP1.ipynb Cell 32\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m data, labels \u001b[39m=\u001b[39m read_cifar(path) \u001b[39m# read the whole dataset\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data_train, labels_train, data_test, labels_test \u001b[39m=\u001b[39m split_dataset(data, labels, \u001b[39m0.9\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_accuracies, test_accuracy \u001b[39m=\u001b[39m run_mlp_training(data_train, labels_train, data_test, labels_test, d_h\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, num_epoch\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32md:\\ECL\\3A\\MOD\\IA\\TD1\\mod_4_6-td1-main\\TP1.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m b2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m, d_out))  \u001b[39m# second layer biaises\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Training\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m w1, b1, w2, b2, train_accuracies \u001b[39m=\u001b[39m train_mlp(w1, b1, w2, b2, data_train, labels_train, learning_rate, num_epoch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Testing\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m test_accuracy \u001b[39m=\u001b[39m test_mlp(w1, b1, w2, b2, data_test, labels_test)\n",
      "\u001b[1;32md:\\ECL\\3A\\MOD\\IA\\TD1\\mod_4_6-td1-main\\TP1.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch : \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# one training step\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m w1, b1, w2, b2, loss, accuracy \u001b[39m=\u001b[39m learn_once_cross_entropy(w1, b1, w2, b2, data_train, labels_train, learning_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss : \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39maccuracy : \u001b[39m\u001b[39m{\u001b[39;00maccuracy\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m train_accuracies\u001b[39m.\u001b[39mappend(accuracy)\n",
      "\u001b[1;32md:\\ECL\\3A\\MOD\\IA\\TD1\\mod_4_6-td1-main\\TP1.ipynb Cell 32\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Compute loss : cross-entropy loss \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m predictions_vect \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(a2, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# the predicted label (i.e. each line of a2) of each input in the batch is the index of the maximum of a2 on each line\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mmean(y\u001b[39m*\u001b[39;49mnp\u001b[39m.\u001b[39;49mlog(predictions_vect))  \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Error backpropagation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/TP1.ipynb#X44sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dc_dz2 \u001b[39m=\u001b[39m a2 \u001b[39m-\u001b[39m targets                          \u001b[39m# dim : N x d_out\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (54000,10) (54000,) "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = \"D:/ECL/3A/MOD/IA/TD1/mod_4_6-td1-main/data/cifar-10-batches-py/\"\n",
    "# Test read_cifar\n",
    "data, labels = read_cifar(path) # read the whole dataset\n",
    "\n",
    "data_train, labels_train, data_test, labels_test = split_dataset(data, labels, 0.9)\n",
    "train_accuracies, test_accuracy = run_mlp_training(data_train, labels_train, data_test, labels_test, d_h=64, learning_rate=0.1, num_epoch=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
